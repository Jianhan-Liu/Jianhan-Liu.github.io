<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="description" content="线性回归模型的Python实现"><meta name="keywords" content="算法,NLP,机器学习,深度学习"><link rel="alternate" href="/atom.xml" title="Freecoder"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.11.0">
<link rel="canonical" href="http://www.freecoder.site/2019/07/15/线性模型的Python实现/">

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css"><link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css"><script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.11.0">

<script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":true,"latex":true};
</script>

    <title>线性回归模型的Python实现 - Freecoder</title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Freecoder</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/">
        <li class="mobile-menu-item">首页
          </li>
      </a><a href="/archives/">
        <li class="mobile-menu-item">归档
          </li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">分类
          </li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Freecoder</a>
</div>

<nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/">
            首页
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            归档
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/categories/">
            分类
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/about/">
            关于
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content"><article class="post">
    <header class="post-header">
      <h1 class="post-title">线性回归模型的Python实现
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-07-15
        </span><span class="post-category">
            <a href="/categories/Python/">Python</a>
            <a href="/categories/机器学习/">机器学习</a>
            </span>
        </div>
    </header>

    <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-随机性选择-theta-0-和-theta-1"><span class="toc-text">1.随机性选择$\theta_0$和$\theta_1$</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-监督式方向调整选择-theta-0-和-theta-1"><span class="toc-text">2.监督式方向调整选择$\theta_0$和$\theta_1$</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-梯度下降选择-theta-0-和-theta-1"><span class="toc-text">3.梯度下降选择$\theta_0$和$\theta_1$</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-方差代价函数"><span class="toc-text">3.1.方差代价函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-绝对值代价函数"><span class="toc-text">3.2.绝对值代价函数</span></a></li></ol></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#4-结论"><span class="toc-text">4.结论</span></a>
    </li></div>
  </div><div class="post-content"><h3 id="1-随机性选择-theta-0-和-theta-1"><a href="#1-随机性选择-theta-0-和-theta-1" class="headerlink" title="1.随机性选择$\theta_0$和$\theta_1$"></a>1.随机性选择$\theta_0$和$\theta_1$</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"></span><br><span class="line">data = load_boston()</span><br><span class="line">X_rm = data[<span class="string">'data'</span>][:, <span class="number">5</span>]</span><br><span class="line">Y = data[<span class="string">'target'</span>]</span><br><span class="line">theta_0 = <span class="number">100</span></span><br><span class="line">theta_1 = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">min_loss = float(<span class="string">'inf'</span>)</span><br><span class="line">flag = <span class="number">1</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> flag:</span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">    y_hat = X_rm * theta_1 + theta_0</span><br><span class="line">    current_loss = np.sum(np.square(Y - y_hat)) / len(Y)</span><br><span class="line">    <span class="keyword">if</span> min_loss &gt; current_loss:</span><br><span class="line">        flag =<span class="number">0</span> <span class="keyword">if</span> min_loss - current_loss &lt; <span class="number">.001</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        min_loss = current_loss</span><br><span class="line">        best_theta_1, best_theta_0 = theta_1, theta_0</span><br><span class="line">    </span><br><span class="line">    theta_0 = random.random() * <span class="number">200</span> - <span class="number">100</span></span><br><span class="line">    theta_1 = random.random() * <span class="number">200</span> - <span class="number">100</span></span><br><span class="line">    </span><br><span class="line">print(<span class="string">f"Sequence <span class="subst">&#123;count&#125;</span>: with loss <span class="subst">&#123;min_loss&#125;</span> when theta_1 = <span class="subst">&#123;best_theta_1&#125;</span>, theta_0 = <span class="subst">&#123;best_theta_0&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>以下输出纯粹随机，多数情况下为了达到0.001的误差，运行次数可能非常大。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sequence <span class="number">819148</span>: <span class="keyword">with</span> loss <span class="number">43.60210733030882</span> when theta_1 = <span class="number">9.150345535429594</span>, theta_0 = <span class="number">-34.95354185708321</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>另一次随机结果。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sequence <span class="number">8002336</span>: <span class="keyword">with</span> loss <span class="number">43.60100211158343</span> when theta_1 = <span class="number">9.132154060693026</span>, theta_0 = <span class="number">-34.86180554948703</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>误差增大两个数量级后。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sequence <span class="number">57349</span>: <span class="keyword">with</span> loss <span class="number">43.88216812932692</span> when theta_1 = <span class="number">8.556675789981298</span>, theta_0 = <span class="number">-30.875293568458332</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">best_y_hat = X_rm * best_theta_1 + best_theta_0</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">plt.scatter(X_rm, Y)</span><br><span class="line">plt.plot(X_rm, best_y_hat, color=<span class="string">'red'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<a id="more"></a>
<center>

<p><img src="./pics/png1.png" alt="png1"></p>
</center>

<h3 id="2-监督式方向调整选择-theta-0-和-theta-1"><a href="#2-监督式方向调整选择-theta-0-和-theta-1" class="headerlink" title="2.监督式方向调整选择$\theta_0$和$\theta_1$"></a>2.监督式方向调整选择$\theta_0$和$\theta_1$</h3><blockquote>
<p>需提前增大两个数量级的误差，否则时间太久了，及<code>min_loss - current_loss &lt; 0.1</code>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">theta_0 = <span class="number">100</span></span><br><span class="line">theta_1 = <span class="number">100</span></span><br><span class="line">direction = [</span><br><span class="line">    (<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="number">-1</span>),</span><br><span class="line">    (<span class="number">-1</span>, <span class="number">1</span>),</span><br><span class="line">    (<span class="number">-1</span>, <span class="number">-1</span>)</span><br><span class="line">]</span><br><span class="line">scalar = <span class="number">.1</span></span><br><span class="line">min_loss = float(<span class="string">'inf'</span>)</span><br><span class="line">new_direction = random.choice(direction)</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line">flag = <span class="number">1</span></span><br><span class="line"><span class="keyword">while</span> flag:</span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">    new_0, new_1 = new_direction</span><br><span class="line">    theta_0, theta_1 = theta_0 + scalar * new_0, theta_1 + scalar * new_1</span><br><span class="line">    </span><br><span class="line">    y_hat = X_rm * theta_1 + theta_0</span><br><span class="line">    current_loss = np.sum(np.square(Y - y_hat)) / len(Y)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> min_loss &gt; current_loss:</span><br><span class="line">        flag = <span class="number">0</span> <span class="keyword">if</span> min_loss - current_loss &lt; <span class="number">.1</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        min_loss = current_loss</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        new_direction = random.choice(direction)</span><br><span class="line">    </span><br><span class="line">print(<span class="string">f"Sequence <span class="subst">&#123;count&#125;</span>: with loss <span class="subst">&#123;min_loss&#125;</span> when theta_1 = <span class="subst">&#123;best_theta_1&#125;</span>, theta_0 = <span class="subst">&#123;best_theta_0&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sequence <span class="number">969</span>: <span class="keyword">with</span> loss <span class="number">61.352506983530255</span> when theta_1 = <span class="number">9.209101739990572</span>, theta_0 = <span class="number">-35.23063139725508</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">best_y_hat = X_rm * best_theta_1 + best_theta_0</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">plt.scatter(X_rm, Y)</span><br><span class="line">plt.plot(X_rm, best_y_hat, color=<span class="string">'red'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<center>

<p><img src="./pics/png2.png" alt="png2"></p>
</center>

<h3 id="3-梯度下降选择-theta-0-和-theta-1"><a href="#3-梯度下降选择-theta-0-和-theta-1" class="headerlink" title="3.梯度下降选择$\theta_0$和$\theta_1$"></a>3.梯度下降选择$\theta_0$和$\theta_1$</h3><h4 id="3-1-方差代价函数"><a href="#3-1-方差代价函数" class="headerlink" title="3.1.方差代价函数"></a>3.1.方差代价函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># %%time</span></span><br><span class="line">learning_rate = <span class="number">1</span> / <span class="number">1000</span></span><br><span class="line">theta_0 = <span class="number">100</span></span><br><span class="line">theta_1 = <span class="number">100</span></span><br><span class="line">min_loss = float(<span class="string">'inf'</span>)</span><br><span class="line">update_count = <span class="number">0</span></span><br><span class="line">flag = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> flag:</span><br><span class="line">    update_count += <span class="number">1</span></span><br><span class="line">    y_hat = X_rm * theta_1 + theta_0</span><br><span class="line">    current_loss = np.sum(np.square(Y - y_hat)) / len(Y)</span><br><span class="line">    <span class="keyword">if</span> min_loss &gt; current_loss:</span><br><span class="line">        flag = <span class="number">0</span> <span class="keyword">if</span> min_loss - current_loss &lt; <span class="number">.000001</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        min_loss = current_loss    </span><br><span class="line">        </span><br><span class="line">    theta_1 = theta_1 - learning_rate * <span class="number">2</span> * np.sum((y_hat - Y) * X_rm) / len(Y)</span><br><span class="line">    theta_0 = theta_0 - learning_rate * <span class="number">2</span> * np.sum(y_hat - Y) / len(Y)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f"<span class="subst">&#123;update_count&#125;</span> iterations with min_loss <span class="subst">&#123;min_loss&#125;</span> to get best theta with theta_0: <span class="subst">&#123;theta_0&#125;</span> and theta_1: <span class="subst">&#123;theta_1&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">187323</span> iterations <span class="keyword">with</span> min_loss <span class="number">43.62134288563148</span> to get best theta <span class="keyword">with</span> theta_0: <span class="number">-33.3716190502384</span> <span class="keyword">and</span> theta_1: <span class="number">8.897899324289263</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">best_y_hat = X_rm * theta_1 + theta_0</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">plt.scatter(X_rm, Y)</span><br><span class="line">plt.plot(X_rm, best_y_hat, color=<span class="string">'red'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<center>

<p><img src="./pics/png3.png" alt="png3"></p>
</center>

<h4 id="3-2-绝对值代价函数"><a href="#3-2-绝对值代价函数" class="headerlink" title="3.2.绝对值代价函数"></a>3.2.绝对值代价函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">1</span> / <span class="number">10000</span></span><br><span class="line">theta_0 = <span class="number">100</span></span><br><span class="line">theta_1 = <span class="number">100</span></span><br><span class="line">min_loss = float(<span class="string">'inf'</span>)</span><br><span class="line">update_count = <span class="number">0</span></span><br><span class="line">flag = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> flag:</span><br><span class="line">    <span class="keyword">if</span> update_count % <span class="number">10000</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">f"<span class="subst">&#123;update_count&#125;</span> iteration: with loss <span class="subst">&#123;min_loss&#125;</span> : theta_1 = <span class="subst">&#123;theta_1&#125;</span>, theta_0 = <span class="subst">&#123;theta_0&#125;</span>"</span>) </span><br><span class="line">    update_count += <span class="number">1</span></span><br><span class="line">    y_hat = X_rm * theta_1 + theta_0</span><br><span class="line">    current_loss = np.sum(np.abs(Y - y_hat)) / len(Y)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> min_loss &gt; current_loss:</span><br><span class="line">        flag = <span class="number">0</span> <span class="keyword">if</span> min_loss - current_loss &lt; <span class="number">.0001</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        min_loss = current_loss    </span><br><span class="line">        </span><br><span class="line">    theta_1 = theta_1 - learning_rate * np.sum(X_rm) / len(Y)</span><br><span class="line">    theta_0 = theta_0 - learning_rate * np.sum(X_rm) / len(Y)</span><br><span class="line">print(<span class="string">f"<span class="subst">&#123;update_count&#125;</span> iterations to get best theta with theta_1 = <span class="subst">&#123;theta_1&#125;</span> theta_0 = <span class="subst">&#123;theta_0&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">154300</span> iterations to get best theta <span class="keyword">with</span> theta_1 = <span class="number">3.0280914034127573</span> theta_0 = <span class="number">3.0280914034127573</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">best_y_hat = X_rm * theta_1 + theta_0</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">plt.scatter(X_rm, Y)</span><br><span class="line">plt.plot(X_rm, best_y_hat, color=<span class="string">'red'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<center>

<p><img src="./pics/png5.png" alt="png4"></p>
</center>

<blockquote>
<p>随机初始值的拟合效果。</p>
</blockquote>
<center>

<p><img src="./pics/png4.png" alt="png4"></p>
</center>

<h2 id="4-结论"><a href="#4-结论" class="headerlink" title="4.结论"></a>4.结论</h2><p>为了方便比较而设定的初始值，会直接影响模型最终的拟合效果，因此即使是梯度下降法中误差再小，也无法弥补初始值对最终曲线的影响。比较模型性能需要从多个方面进行考量，单从迭代次数而言过于片面，还需要考虑最终的拟合情况。可以肯定的是，对比前两种随机过程，梯度下降的效率要高几个数量级。</p>

      </div>
      
      <footer class="post-footer">
        
        <nav class="post-nav"><a class="prev" href="/2019/07/16/2-Gram语言模型的Python实现/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">2-Gram语言模型及基于模式匹配对话A.I的Python实现</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    <a class="next" href="/2019/07/14/北京地铁智能搜索系统/">
        <span class="next-text nav-default">北京地铁智能搜索系统的Python实现</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    </nav></footer>
    </article></div><div class="comments" id="comments"></div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:liujianhan@gmail.com" class="iconfont icon-email" title="email"></a>
        <a href="https://github.com/jianhan-liu" class="iconfont icon-github" title="github"></a>
        <a href="https://www.douban.com/people/mrserious/" class="iconfont icon-douban" title="douban"></a>
        </div><div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">&copy;2019<span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Django</span>
  </span>
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人</span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div><script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  <script type="text/javascript" src="/js/src/even.js?v=2.11.0"></script>
</body>
</html>
